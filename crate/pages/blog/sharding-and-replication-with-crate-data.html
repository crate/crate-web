title: Sharding And Replication With Crate
link: https://crate.io/blog/sharding-and-replication-with-crate-data/
author: Sebastian Utz
description: Crate has built-in support for sharding and replication. One of the finest things about Crate is it eliminates need to glue number of technologies together to achieve your big data dream and thus is a breeze for developers.
created: 2014/09/09 12:28:30
post_name: sharding-and-replication-with-crate-data
status: private
post_type: post
tags: sharding, replication, crate
category: news, developer-news

With the vast rise in the size of business data and amount of transaction of data, the traditional single database instance is no more a desired infrastructure configuration for most applications. Sharding is increasingly popular method in any data storage system and is a favorite choice for scaling the read and write throughput. For any data-centric application, the data grows much more rapidly and thus, the traditional vertical scaling approach which involves more and more computing power on a single machine soon starts to become a costly and there is always a practical limit to what we can scale vertically. With sharding, the entire data set is distributed over number of nodes as shards thus reducing the number of operations each shard has to handle and making it possible to store massive amount of data while still scaling in terms of data related operations.

Crate has built-in support for [sharding and replication](https://crate.io/docs/stable/sql/ddl.html#sharding). One of the finest things about Crate is it eliminates need to glue number of technologies together to achieve your big data dream and thus is a breeze for developers. Crate further simplifies database sharding and replication since it performs automatic sharding and replication thus reducing overhead for datastore administrators. Crate can poke the entire network (including local server) for any Crate nodes and starts replicating and sharding behind the scene. No “data-admin-fu” needed. This eliminates the need for keeping an eye on auxillary tasks and lets the team focus on the priority tasks. Sharding in Crate supports normal data as well as blobs. Crate allows you to perform sharding and replication of your cluster on a per-table basis which means its as easy as specifying the number of shards and number of replicas in a `CREATE TABLE` statement.

The number of shards can be defined by appending the `CLUSTERED INTO x SHARDS` into the table creation statement. With Crate, sharding support is native and Crate uses 5 shards by default if not defined. Since Crate uses Elasticsearch under the hood for sharding and replication, Crate uses a hash/modulo sharding. As of now, Crate only allows you to define number of shards on table creation for unpartitioned tables. In case of partitioned tables, the shards can be configured during the creation of partitions.

Below is an example of defining shards in crash console: 
    
    
    cr> connect techgaun:4200;
    cr> create table outlets (
    ... outlet_id int primary key,
    ... outlet_name string,
    ... region string
    ... ) clustered into 6 shards;
    CREATE OK (0.821 sec)

With the introduction of sharding, there comes a problem of identifying shard to which a particular document belongs to. This is where routing comes into play. Your cluster might have 10 shards or even thousand shards. However, a particular document is only located in one of them. Routing provides a valuable information of where the document must be stored, shard 1 or shard 2 or so on which is useful for future retrieval of data in sharding environment. Thus, routing can be used to ensure that only those shards with the relevant data are hit by your query. By default, primary key columns are chosen for routing and thus, routing definition can be omitted for the tables containing primary key constraints. However, a custom routing can be explicitly defined. For a table with primary key columns, routing column is expected to match one of the primary key column(s). Custom routing and defining number of shards can be combined on a single statement. Below is an example of custom routing: 
    
    
    cr> create table outlets (
    ...   outlet_id int,
    ...   outlet_name string,
    ...   outlet_region string,
    ...   primary key (outlet_id, outlet_region)
    ... ) clustered by (outlet_region) into 6 shards;
    CREATE OK (0.591 sec)

**Note: If you wish to get details about shards, the table sys.shards stores all the real-time statistics for all shards of all non-system tables.**
    
    cr> select * from sys.shards;
    +-------------+------------+----+-----------------+----------+---------+-----------------+------+------------+------------------+
    | schema_name | table_name | id | partition_ident | num_docs | primary | relocating_node | size | state      | orphan_partition |
    +-------------+------------+----+-----------------+----------+---------+-----------------+------+------------+------------------+
    | doc         | outlets    |  4 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  4 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  0 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  0 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  3 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  3 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  1 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  1 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  2 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  2 |                 |        0 | FALSE   |            NULL |    0 | UNASSIGNED | FALSE            |
    | doc         | outlets    |  0 |                 |        0 | TRUE    |            NULL |  123 | STARTED    | FALSE            |
    | doc         | outlets    |  1 |                 |        0 | TRUE    |            NULL |   87 | STARTED    | FALSE            |
    | doc         | outlets    |  2 |                 |        0 | TRUE    |            NULL |  123 | STARTED    | FALSE            |
    | doc         | outlets    |  3 |                 |        0 | TRUE    |            NULL |   87 | STARTED    | FALSE            |
    | doc         | outlets    |  4 |                 |        0 | TRUE    |            NULL |  123 | STARTED    | FALSE            |
    +-------------+------------+----+-----------------+----------+---------+-----------------+------+------------+------------------+

Replication is an essential element for highly available data stores and since Crate aims to be one, it offers support for replication on table-basis. Replication is primarily helpful for real good read performance and thus is a good candidate for business intelligence tools where data are mostly read. Replication of a table in Crate means that each primary shard of a table is stored additionally on so called secondary shards. Crate by default creates one replica thus the content of table is stored twice across the cluster nodes.

Unlike sharding, the number of replicas can be adjusted any time in Crate.

Below is an example of creation of replicas in Crate:

    cr> create table outlets (
    ...   outlet_id int,
    ...   outlet_name string,
    ...   outlet_region string,
    ...   primary key (outlet_id, outlet_region)
    ... ) with (number_of_replicas = 2);
    CREATE OK (0.485 sec)

You can combine them all:

    cr> create table outlets (
    ...   outlet_id int,
    ...   outlet_name string,
    ...   outlet_region string,
    ...   primary key (outlet_id, outlet_region)
    ... ) clustered by (outlet_region) into 5 shards with (number_of_replicas = 2);
    CREATE OK (0.488 sec)

Now, you can query the information_schema.tables so as to see your create table in effect:

    cr> select * from information_schema.tables where table_name = 'outlets';
    +-------------+------------+------------------+--------------------+---------------+----------------+
    | schema_name | table_name | number_of_shards | number_of_replicas | clustered_by  | partitioned_by |
    +-------------+------------+------------------+--------------------+---------------+----------------+
    | doc         | outlets    |                5 |                  2 | outlet_region |           NULL |
    +-------------+------------+------------------+--------------------+---------------+----------------+
    SELECT 1 row in set (0.162 sec)

Replication can be further fine grained in Crate by specifying range of minimum to maximum number of replicas depending on the number of nodes in the cluster. The [Crate Documentation](https://crate.io/docs/stable/sql/ddl.html#replication) describes some of the scenarios with the description.

The example below creates a table outlets which requires at least 2 replicas to be fully replicated and with the addition of nodes, the maximum replicas count can reach 6.

    cr> create table outlets (
    ... outlet_id int,
    ... outlet_name string,
    ... outlet_region string,
    ... primary key (outlet_id, outlet_region)
    ... ) clustered by (outlet_region) into 5 shards with (number_of_replicas = '2-6');
    CREATE OK (0.918 sec)

The number of replicas can be changed at any time. Below is an example of the update:

    cr> update outlets set number_of_replica='0-all';
    UPDATE OK, 7 rows affected (0.377 sec)

Also note that Crate Data offers a RESTful SQL endpoint to run SQL queries against Crate datastore and is accessible via `<server:port>/_sql`.

